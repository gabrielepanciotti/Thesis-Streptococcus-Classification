{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import messagebox\n",
    "from tkinter import TclError, ttk\n",
    "\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from scipy.spatial import distance\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, make_scorer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, StratifiedKFold, KFold, GridSearchCV, RandomizedSearchCV, ParameterGrid\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, LassoCV, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.base import clone\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import model_selection\n",
    "from sklearn.semi_supervised import LabelPropagation, LabelSpreading\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.set_printoptions(precision=5, suppress=True)\n",
    "RANDOM_STATE = 46\n",
    "N_JOBS = -1\n",
    "class_names = [\"Canis\", \"Dysg. Equisimilis\", \"Dysg. Dysgalactiae\"]\n",
    "map_target = {\n",
    "    \"Streptococcus canis\": 2,\n",
    "    \"Streptococcus dysgalactiae subsp. dysgalactiae\": 1,\n",
    "    \"Streptococcus dysgalactiae subsp. equisimilis\": 0\n",
    "}\n",
    "map_target_inv = {\n",
    "    2: \"Canis\",\n",
    "    1: \"Dysgalactiae\",\n",
    "    0: \"Equisimilis\"\n",
    "}\n",
    "map_target_antibiotici = {\n",
    "    \"S\" : 1,\n",
    "    \"NS\" : 0\n",
    "}\n",
    "map_target_antibiotici_inv = {\n",
    "    1 : \"S\",\n",
    "    0 : \"NS\"\n",
    "}\n",
    "maps_cluster = {\n",
    "    2 : 0,\n",
    "    1 : 2,\n",
    "    0 : 1\n",
    "}\n",
    "metrics = ['accuracy', 'recall_weighted', 'precision_weighted','f1_weighted']\n",
    "metrics_cluster = ['Silhouette', 'Calinski', 'Davies']\n",
    "skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "start = 2\n",
    "n_antibiotici = 9\n",
    "n_geni = 27\n",
    "n_virulenza = 18\n",
    "scaled = ''\n",
    "scaler = ''\n",
    "tutti_picchi = 'tutti_picchi_'\n",
    "reduction = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for standard scaling\n",
    "def standard_scaler(X_train, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "# Define a function for dimensionality reduction using PCA\n",
    "def dimensionality_reduction(X_train, X_test, n_components):\n",
    "    X_train.columns = X_train.columns.astype(str)\n",
    "    X_test.columns = X_test.columns.astype(str)\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    X_train_pca = pd.DataFrame(X_train_pca)\n",
    "    X_test_pca = pd.DataFrame(X_test_pca)\n",
    "    #print(X_train_pca.shape)\n",
    "    return X_train_pca, X_test_pca\n",
    "\n",
    "def dimensionality_reduction_cluster(X, n_components):\n",
    "    X.columns = X.columns.astype(str)\n",
    "    print(X.shape)\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    X_pca = pd.DataFrame(X_pca, index=X.index.to_list())\n",
    "    print(X_pca.shape)\n",
    "    X_pca.columns = X_pca.columns.astype(str)\n",
    "    return X_pca\n",
    "\n",
    "def makeScoreMeanWithoutNaN(metrics):\n",
    "    for name, metrica in metrics.items():\n",
    "        print(name)\n",
    "        print(metrics[name])\n",
    "        metrics[name] = metrics[name][~np.isnan(metrics[name])]\n",
    "        print(metrics[name])\n",
    "        metrics[name] = np.mean(metrics[name])\n",
    "        print(metrics[name])\n",
    "    print(metrics)\n",
    "    return metrics\n",
    "\n",
    "def makeScore(y_test, y_pred):\n",
    "    score = {}\n",
    "\n",
    "    score['acc'] = accuracy_score(y_test, y_pred)\n",
    "    score['b_acc'] = balanced_accuracy_score(y_test, y_pred)\n",
    "    score['st'] = score['acc'].std()\n",
    "    score['prec'] = precision_score(y_test, y_pred, average='weighted')\n",
    "    score['rec'] = recall_score(y_test, y_pred, average='weighted')\n",
    "    score['f1'] = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    return score\n",
    "\n",
    "def makeCrossValidation(model, X_train, y_train):\n",
    "    score = {}\n",
    "    cv = cross_validate(estimator=model, X=X_train, y=y_train,\n",
    "                        scoring=metrics, cv=skfold,\n",
    "                        n_jobs=N_JOBS, verbose=0)\n",
    "\n",
    "    score['acc'] = cv.get('test_accuracy').mean()\n",
    "    score['st'] = cv.get('test_accuracy').std()\n",
    "    score['prec'] = cv.get('test_precision_weighted').mean()\n",
    "    score['rec'] = cv.get('test_recall_weighted').mean()\n",
    "    score['f1'] = cv.get('test_f1_weighted').mean()\n",
    "\n",
    "    return score\n",
    "\n",
    "def makeCrossValidationCluster(model, X):\n",
    "    model.fit(X)\n",
    "    labels = model.labels_\n",
    "    pca = PCA(n_components = 2)\n",
    "    pca.fit(X)\n",
    "    X_pca = pca.transform(X)\n",
    "    avg_silhouette = silhouette_score(X_pca, labels)\n",
    "    avg_calinski_harabasz = calinski_harabasz_score(X_pca, labels)\n",
    "    avg_davies_bouldin = davies_bouldin_score(X_pca, labels)\n",
    "\n",
    "    score = {}\n",
    "    score['Silhouette'] = avg_silhouette\n",
    "    score['Calinski'] = avg_calinski_harabasz\n",
    "    score['Davies'] = avg_davies_bouldin\n",
    "\n",
    "    return score\n",
    "\n",
    "N_CLUSTERS = 3\n",
    "list_animals = ['Dog', 'Cat', 'Bovine', 'Swine', 'Ovine', 'Goat', 'Hedgehog',\n",
    "       'Horse', 'Donkey', 'Wolf', 'Reference strain (CCUG)',\n",
    "       'Water buffalo','Wild boar']\n",
    "list_animals_agg = ['Animal species of origin_Bovine', 'Animal species of origin_Cat',\n",
    "       'Animal species of origin_Dog', 'Animal species of origin_Donkey',\n",
    "       'Animal species of origin_Goat', 'Animal species of origin_Hedgehog',\n",
    "       'Animal species of origin_Horse', 'Animal species of origin_Ovine',\n",
    "       'Animal species of origin_Reference strain (CCUG)',\n",
    "       'Animal species of origin_Swine',\n",
    "       'Animal species of origin_Water buffalo',\n",
    "       'Animal species of origin_Wolf',\n",
    "       'Animal species of origin_Wild boar']\n",
    "list_haem = ['Haemolysis_a', 'Haemolysis_b']\n",
    "list_subs = [\"K-means_Canis\", \"K-means_Dysgalactiae\", \"K-means_Equisimilis\"]\n",
    "\n",
    "models = {\n",
    "  'LogisticRegression': LogisticRegression(random_state=RANDOM_STATE),\n",
    "  'Ridge' : RidgeClassifier(random_state=RANDOM_STATE),\n",
    "  #'DecisionTree': DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "  #'K-nn': KNeighborsClassifier(),\n",
    "  'RandomForest': RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "  'BernoulliNB': BernoulliNB(),\n",
    "  'GaussianNB': GaussianNB(),\n",
    "  #'NearestCentroid': NearestCentroid(),\n",
    "  'SVC' : SVC(),\n",
    "  'LinearSVC' : LinearSVC(),\n",
    "  'LabelPropagation' : LabelPropagation(),\n",
    "  'LabelSpreading' : LabelSpreading(),\n",
    "  'SGDClassifier' : SGDClassifier()\n",
    "  #'stack' : StackingCVClassifier\n",
    "}\n",
    "\n",
    "models_cluster = [\n",
    "  'K-means',\n",
    "  #'AgglomerativeClustering'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_data(path):\n",
    "    window = tk.Tk()\n",
    "    window.title(\"Excel Viewer\")\n",
    "    workbook = openpyxl.load_workbook(path)\n",
    "    sheet = workbook.active\n",
    "\n",
    "    list_values = list(sheet.values)\n",
    "    cols = list_values[0]\n",
    "    tree = ttk.Treeview(window, column= cols, show=\"headings\")\n",
    "    for col_name in cols:\n",
    "        tree.heading(col_name, text = col_name)\n",
    "    tree.pack(expand=True, fill='x')\n",
    "    \n",
    "    for value_tuple in list_values[1:]:\n",
    "        tree.insert('',tk.END, values=value_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(self, features, targets, n):\n",
    "    df = pd.read_csv(self.file_path,\n",
    "                        delimiter=';', index_col='ID Strain')\n",
    "    display(df)\n",
    "    maldi = df.iloc[:,start:start+n]\n",
    "    maldi.fillna(0, inplace=True)\n",
    "    maldi = maldi.replace(',', '.', regex=True)\n",
    "    columns = maldi.columns\n",
    "    for column in columns:\n",
    "        maldi[column] = maldi[column].astype(float)\n",
    "    display(maldi)\n",
    "    \n",
    "    col = maldi.columns.to_list()\n",
    "    col = [i.replace(',', '.') for i in col]\n",
    "    col = [int(float(i)) for i in col]\n",
    "\n",
    "    maldi.columns = col\n",
    "    \n",
    "    for i in range(2000,16500):\n",
    "        if i not in maldi.columns:\n",
    "            maldi[i] = 0\n",
    "    maldi = maldi.reindex(sorted(maldi.columns), axis=1)\n",
    "    maldi = maldi.fillna(0)\n",
    "    \n",
    "    maldi.columns = maldi.columns.astype(str)\n",
    "    data = maldi\n",
    "    \n",
    "    for feature in features:\n",
    "        if feature == 'Specie animale':\n",
    "            animals = df.iloc[:,0]\n",
    "            #display(animals)\n",
    "            animals_dummies = pd.DataFrame.from_dict(pd.get_dummies(animals))\n",
    "            if ('Specie animale' and 'Haemolysis') in features:\n",
    "                str_df = 'agg'\n",
    "                columns = animals_dummies.columns\n",
    "                for column in columns:\n",
    "                    animals_dummies.rename(columns = {column : 'Animal species of origin_'+column}, inplace=True)\n",
    "                missing_cols_animals = set(list_animals_agg) - set(animals_dummies.columns)\n",
    "                # Add a missing column in test set with default value equal to 0\n",
    "                for c in missing_cols_animals:\n",
    "                    animals_dummies[str(c)] = 0\n",
    "                # Ensure the order of column in the test set is in the same order than in train set\n",
    "                animals_dummies = animals_dummies[list_animals_agg]\n",
    "            else:\n",
    "                str_df = 'animals'\n",
    "                missing_cols_animals = set(list_animals) - set(animals_dummies.columns)\n",
    "                # Add a missing column in test set with default value equal to 0\n",
    "                for c in missing_cols_animals:\n",
    "                    animals_dummies[str(c)] = 0\n",
    "                # Ensure the order of column in the test set is in the same order than in train set\n",
    "                animals_dummies = animals_dummies[list_animals]\n",
    "        if feature == 'Haemolysis':\n",
    "            haem = df.iloc[:,1]\n",
    "            #display(haem)\n",
    "            if 'Specie animale' not in features:\n",
    "                str_df = 'hae'\n",
    "            haem_dummies = pd.DataFrame.from_dict(pd.get_dummies(haem))\n",
    "            haem_dummies.rename(columns = {'a' : 'Haemolysis_a', 'b' : 'Haemolysis_b'}, inplace=True)\n",
    "            missing_cols_haem = set(list_haem) - set(haem_dummies.columns)\n",
    "            for c in missing_cols_haem:\n",
    "                haem_dummies[str(c)] = 0\n",
    "            haem_dummies = haem_dummies[list_haem]\n",
    "    \n",
    "            \n",
    "    \n",
    "    data = pd.concat([data,animals_dummies], axis=1)\n",
    "    data = pd.concat([data,haem_dummies], axis=1)\n",
    "    display(data)\n",
    "    \n",
    "    targets_col = list()\n",
    "    for target in targets:\n",
    "        if target == 'Sottospecie':\n",
    "            targets_col.append('subspecies')\n",
    "        else:\n",
    "            targets_col.append(target)\n",
    "    print(targets_col)\n",
    "    \n",
    "    str_df = str_df+'_npicchi306'\n",
    "    return data, str_df, targets_col\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_cluster(X, y, str_df):\n",
    "  pred_cluster = pd.DataFrame()\n",
    "\n",
    "  #Dataframe con risultati metriche per ogni modello\n",
    "  metrics_df_cluster = pd.DataFrame(columns=['Target', 'Dataframe', 'Model',\n",
    "                              'Silhouette', 'Calinski', 'Davies'])\n",
    "\n",
    "  for name in models_cluster:\n",
    "    print(\"Modello \"+name)\n",
    "    model = pickle.load(open('../models/cluster_'+tutti_picchi+str_df+'_'+name+'.pkl', \"rb\"))\n",
    "    y_pred = model.predict(X)\n",
    "    y_pred = pd.DataFrame(y_pred,X.index)\n",
    "    pred_cluster[name] = y_pred\n",
    "  pred_cluster.index = X.index \n",
    "  pred_cluster.to_csv('../new_prediction/cluster_'+str_df+'.csv', index = True)  \n",
    "  display(pred_cluster)\n",
    "  return pred_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('winnative', 'clam', 'alt', 'default', 'classic', 'vista', 'xpnative')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1264.0_x64__qbz5n2kfra8p0\\Lib\\tkinter\\__init__.py\", line 1948, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_40576\\4141399178.py\", line 62, in <lambda>\n",
      "    command=lambda: print(self.target_case_check[var].get()))\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Checkbutton' object has no attribute 'get'\n",
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.1264.0_x64__qbz5n2kfra8p0\\Lib\\tkinter\\__init__.py\", line 1948, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\gabri\\AppData\\Local\\Temp\\ipykernel_40576\\4141399178.py\", line 62, in <lambda>\n",
      "    command=lambda: print(self.target_case_check[var].get()))\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'Checkbutton' object has no attribute 'get'\n"
     ]
    }
   ],
   "source": [
    "class AIModelApp:\n",
    "\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Streptococcus Subspecies Predictor\")\n",
    "        self.root.resizable(0, 0)\n",
    "\n",
    "        '''try:\n",
    "            # windows only (remove the minimize/maximize button)\n",
    "            self.root.attributes('-toolwindow', True)\n",
    "        except TclError:\n",
    "            print('Not supported on your platform')'''\n",
    "        \n",
    "        self.root.columnconfigure(0, weight=4)\n",
    "        self.root.columnconfigure(1, weight=1)\n",
    "        self.file_path = None\n",
    "\n",
    "        feature_vars = [\"Specie animale\", \"Haemolysis\"]\n",
    "        target_vars = [\"Sottospecie\", \"Clindamicina\", \"IsaE\"]\n",
    "\n",
    "        self.frame = ttk.Frame(root)\n",
    "\n",
    "        # grid layout for the input frame\n",
    "        self.frame.columnconfigure(0, weight=1)\n",
    "        self.frame.columnconfigure(0, weight=3)\n",
    "        # Find what\n",
    "        ttk.Label(self.frame, text='Anteprima File:').grid(column=0, row=0, sticky=tk.W)\n",
    "\n",
    "        # Replace with:\n",
    "        ttk.Label(self.frame, text='Numero picchi:').grid(column=0, row=1, sticky=tk.W)\n",
    "        self.num_picchi_entry = ttk.Entry(self.frame)\n",
    "        self.num_picchi_entry.insert(0, \"56\")\n",
    "        self.num_picchi_entry.grid(column=1, row=1, sticky=tk.W)\n",
    "        \n",
    "        ttk.Label(self.frame, text='Features aggiuntive:').grid(column=0, row=2, sticky=tk.W)\n",
    "        # Match Case checkbox\n",
    "        row = 3\n",
    "        self.feat_case = {}\n",
    "        self.feat_case_check = {}\n",
    "        for var in feature_vars:\n",
    "            self.feat_case[var] = tk.StringVar()\n",
    "            self.feat_case_check[var] = ttk.Checkbutton(\n",
    "                self.frame,\n",
    "                text=var,\n",
    "                variable=self.feat_case[var],\n",
    "                onvalue=var,\n",
    "                offvalue='')\n",
    "            self.feat_case_check[var].grid(column=0, row=row, sticky=tk.W)\n",
    "            row += 1\n",
    "\n",
    "        ttk.Label(self.frame, text='Target ricercati:').grid(column=1, row=2, sticky=tk.W)\n",
    "        # Match Case checkbox\n",
    "        row = 3\n",
    "        self.target_case = {}\n",
    "        self.target_case_check = {}\n",
    "        for var in target_vars:\n",
    "            self.target_case[var] = tk.StringVar()\n",
    "            self.target_case_check[var] = ttk.Checkbutton(\n",
    "                self.frame,\n",
    "                text=var,\n",
    "                variable=self.target_case[var],\n",
    "                command=lambda: print(self.target_case_check[var].get()))\n",
    "            self.target_case_check[var].grid(column=1, row=row, sticky=tk.W)\n",
    "            row += 1\n",
    "\n",
    "        for widget in self.frame.winfo_children():\n",
    "            widget.grid(padx=5, pady=5)\n",
    "\n",
    "        self.frame.grid(column=0, row=0)\n",
    "\n",
    "        button_frame = ttk.Frame(root)\n",
    "\n",
    "        button_frame.columnconfigure(0, weight=1)\n",
    "\n",
    "        ttk.Button(button_frame, text='Carica file XLSX', command=self.load_file).grid(column=0, row=0)\n",
    "        ttk.Button(button_frame, text='Avvia previsione', command=self.predict).grid(column=0, row=1)\n",
    "        ttk.Button(button_frame, text='Cancella').grid(column=0, row=2)\n",
    "        ttk.Button(button_frame, text='Esci').grid(column=0, row=3)\n",
    "\n",
    "        for widget in button_frame.winfo_children():\n",
    "            widget.grid(padx=5, pady=5)\n",
    "        button_frame.grid(column=1, row=0)\n",
    "        '''self.predict_button = tk.Button(self.root, text=\"Avvia previsione\", command=self.predict, height=2, width=20)\n",
    "        self.predict_button.pack(pady=10)'''\n",
    "\n",
    "    def load_file(self):\n",
    "        self.file_path = filedialog.askopenfilename(filetypes=[(\"Xlsx File\", \"*.xlsx\")])\n",
    "        preview_data(self.file_path)\n",
    "\n",
    "    def predict(self):\n",
    "        if self.file_path is None:\n",
    "            messagebox.showerror(\"Errore\", \"Carica prima un file CSV!\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            num_picchi = int(self.num_picchi_entry.get())\n",
    "        except ValueError:\n",
    "            messagebox.showerror(\"Errore\", \"Inserisci un numero valido per i picchi!\")\n",
    "            return\n",
    "        \n",
    "        features = [var for var, checkbox in self.feature_vars_checkbox.items() if checkbox.get()]\n",
    "        targets = [var for var, checkbox in self.target_vars_checkbox.items() if checkbox.get()]\n",
    "        print(features)\n",
    "        print(targets)\n",
    "        data, str_df, targets_col = load_data(self, features, targets, num_picchi)\n",
    "        print(data.columns)\n",
    "        #data = pd.read_csv(self.file_path)\n",
    "        if 'subspecies' in targets_col:\n",
    "            y = 'subspecies'\n",
    "            pred_cluster = prediction_cluster(data, y, str_df)\n",
    "            data_cluster = pd.concat([data, pred_cluster], axis = 1)\n",
    "        X = data\n",
    "        prediction = {}\n",
    "        for target in targets_col:\n",
    "            prediction[target] = pd.DataFrame(index = X.index)\n",
    "            '''if target == 'subspecies':\n",
    "                X = data_cluster\n",
    "            else:\n",
    "                x = data'''\n",
    "            for name in models:\n",
    "                #print(\"Modello \"+name)\n",
    "                path = '../models/models_base/'+name+'_'+tutti_picchi+reduction+scaled+scaler+target+'_'+str_df+'.pkl'\n",
    "                print(path)\n",
    "                model = pickle.load(open(path, 'rb'))\n",
    "\n",
    "                y_pred = model.predict(X)\n",
    "                prediction[target][name] = y_pred\n",
    "            prediction[target].index = X.index\n",
    "            \n",
    "            #Aggiunge i valori del target nei dizionari\n",
    "            prediction[target].to_csv('../new_prediction/'+target+tutti_picchi+reduction+scaled+scaler+'_basemodel_'+name+'_'+str_df+'.csv', index = True)\n",
    "            display(prediction[target])\n",
    "        \n",
    "        prediction = pd.DataFrame(index = X.index)\n",
    "        for target in targets_col:\n",
    "            model = pickle.load(open('../models/stack_'+tutti_picchi+reduction+scaled+scaler+target+'_'+str_df+'.pkl', \"rb\"))\n",
    "            print(model)\n",
    "            y_pred = model.predict(X)\n",
    "            display(y_pred)\n",
    "            prediction[target] = y_pred\n",
    "            if (target == 'Clindamicina'):\n",
    "                prediction[target] = prediction[target].map(map_target_antibiotici_inv)\n",
    "            if (target == 'subspecies'):\n",
    "                prediction[target] = prediction[target].map(map_target_inv)\n",
    "        prediction.to_csv('../new_prediction/stack_'+tutti_picchi+reduction+scaled+scaler+str_df+'.csv', index = True)\n",
    "        display(prediction)\n",
    "        \n",
    "        # Mostra i risultati della previsione in una nuova finestra\n",
    "        result_window = tk.Toplevel(self.root)\n",
    "        result_window.title(\"Risultato previsione\")\n",
    "        result_window.geometry(\"300x100\")\n",
    "\n",
    "        for target in targets:\n",
    "            result_label = tk.Label(result_window, text=f\"Risultato {target} previsione: {prediction[target]}\")\n",
    "            result_label.pack(pady=20)\n",
    "\n",
    "        # Pulsante per chiudere la finestra\n",
    "        close_button = tk.Button(result_window, text=\"Esci\", command=result_window.destroy)\n",
    "        close_button.pack()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    style = ttk.Style(root)\n",
    "    print(style.theme_names())\n",
    "    root.tk.call(\"source\", \"forest-light.tcl\")\n",
    "    root.tk.call(\"source\", \"forest-dark.tcl\")\n",
    "    style.theme_use(\"forest-dark\")\n",
    "    app = AIModelApp(root)\n",
    "    root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
