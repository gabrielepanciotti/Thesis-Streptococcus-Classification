{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import messagebox\n",
    "from tkinter import TclError, ttk\n",
    "\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from scipy.spatial import distance\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, make_scorer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, StratifiedKFold, KFold, GridSearchCV, RandomizedSearchCV, ParameterGrid\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, LassoCV, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.base import clone\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import model_selection\n",
    "from sklearn.semi_supervised import LabelPropagation, LabelSpreading\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.set_printoptions(precision=5, suppress=True)\n",
    "RANDOM_STATE = 46\n",
    "N_JOBS = -1\n",
    "class_names = [\"Canis\", \"Dysg. Equisimilis\", \"Dysg. Dysgalactiae\"]\n",
    "map_target = {\n",
    "    \"Streptococcus canis\": 2,\n",
    "    \"Streptococcus dysgalactiae subsp. dysgalactiae\": 1,\n",
    "    \"Streptococcus dysgalactiae subsp. equisimilis\": 0\n",
    "}\n",
    "map_target_inv = {\n",
    "    2: \"Canis\",\n",
    "    1: \"Dysgalactiae\",\n",
    "    0: \"Equisimilis\"\n",
    "}\n",
    "map_target_antibiotici = {\n",
    "    \"S\" : 1,\n",
    "    \"NS\" : 0\n",
    "}\n",
    "map_target_antibiotici_inv = {\n",
    "    1 : \"S\",\n",
    "    0 : \"NS\"\n",
    "}\n",
    "maps_cluster = {\n",
    "    2 : 0,\n",
    "    1 : 2,\n",
    "    0 : 1\n",
    "}\n",
    "metrics = ['accuracy', 'recall_weighted', 'precision_weighted','f1_weighted']\n",
    "metrics_cluster = ['Silhouette', 'Calinski', 'Davies']\n",
    "skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "start = 2\n",
    "n_antibiotici = 9\n",
    "n_geni = 27\n",
    "n_virulenza = 18\n",
    "scaled = ''\n",
    "scaler = ''\n",
    "tutti_picchi = 'tutti_picchi_'\n",
    "reduction = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for standard scaling\n",
    "def standard_scaler(X_train, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "# Define a function for dimensionality reduction using PCA\n",
    "def dimensionality_reduction(X_train, X_test, n_components):\n",
    "    X_train.columns = X_train.columns.astype(str)\n",
    "    X_test.columns = X_test.columns.astype(str)\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    X_train_pca = pd.DataFrame(X_train_pca)\n",
    "    X_test_pca = pd.DataFrame(X_test_pca)\n",
    "    #print(X_train_pca.shape)\n",
    "    return X_train_pca, X_test_pca\n",
    "\n",
    "def dimensionality_reduction_cluster(X, n_components):\n",
    "    X.columns = X.columns.astype(str)\n",
    "    print(X.shape)\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    X_pca = pd.DataFrame(X_pca, index=X.index.to_list())\n",
    "    print(X_pca.shape)\n",
    "    X_pca.columns = X_pca.columns.astype(str)\n",
    "    return X_pca\n",
    "\n",
    "def makeScoreMeanWithoutNaN(metrics):\n",
    "    for name, metrica in metrics.items():\n",
    "        print(name)\n",
    "        print(metrics[name])\n",
    "        metrics[name] = metrics[name][~np.isnan(metrics[name])]\n",
    "        print(metrics[name])\n",
    "        metrics[name] = np.mean(metrics[name])\n",
    "        print(metrics[name])\n",
    "    print(metrics)\n",
    "    return metrics\n",
    "\n",
    "def makeScore(y_test, y_pred):\n",
    "    score = {}\n",
    "\n",
    "    score['acc'] = accuracy_score(y_test, y_pred)\n",
    "    score['b_acc'] = balanced_accuracy_score(y_test, y_pred)\n",
    "    score['st'] = score['acc'].std()\n",
    "    score['prec'] = precision_score(y_test, y_pred, average='weighted')\n",
    "    score['rec'] = recall_score(y_test, y_pred, average='weighted')\n",
    "    score['f1'] = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    return score\n",
    "\n",
    "def makeCrossValidation(model, X_train, y_train):\n",
    "    score = {}\n",
    "    cv = cross_validate(estimator=model, X=X_train, y=y_train,\n",
    "                        scoring=metrics, cv=skfold,\n",
    "                        n_jobs=N_JOBS, verbose=0)\n",
    "\n",
    "    score['acc'] = cv.get('test_accuracy').mean()\n",
    "    score['st'] = cv.get('test_accuracy').std()\n",
    "    score['prec'] = cv.get('test_precision_weighted').mean()\n",
    "    score['rec'] = cv.get('test_recall_weighted').mean()\n",
    "    score['f1'] = cv.get('test_f1_weighted').mean()\n",
    "\n",
    "    return score\n",
    "\n",
    "def makeCrossValidationCluster(model, X):\n",
    "    model.fit(X)\n",
    "    labels = model.labels_\n",
    "    pca = PCA(n_components = 2)\n",
    "    pca.fit(X)\n",
    "    X_pca = pca.transform(X)\n",
    "    avg_silhouette = silhouette_score(X_pca, labels)\n",
    "    avg_calinski_harabasz = calinski_harabasz_score(X_pca, labels)\n",
    "    avg_davies_bouldin = davies_bouldin_score(X_pca, labels)\n",
    "\n",
    "    score = {}\n",
    "    score['Silhouette'] = avg_silhouette\n",
    "    score['Calinski'] = avg_calinski_harabasz\n",
    "    score['Davies'] = avg_davies_bouldin\n",
    "\n",
    "    return score\n",
    "\n",
    "N_CLUSTERS = 3\n",
    "list_animals = ['Dog', 'Cat', 'Bovine', 'Swine', 'Ovine', 'Goat', 'Hedgehog',\n",
    "       'Horse', 'Donkey', 'Wolf', 'Reference strain (CCUG)',\n",
    "       'Water buffalo','Wild boar']\n",
    "list_animals_agg = ['Animal species of origin_Bovine', 'Animal species of origin_Cat',\n",
    "       'Animal species of origin_Dog', 'Animal species of origin_Donkey',\n",
    "       'Animal species of origin_Goat', 'Animal species of origin_Hedgehog',\n",
    "       'Animal species of origin_Horse', 'Animal species of origin_Ovine',\n",
    "       'Animal species of origin_Reference strain (CCUG)',\n",
    "       'Animal species of origin_Swine',\n",
    "       'Animal species of origin_Water buffalo',\n",
    "       'Animal species of origin_Wolf',\n",
    "       'Animal species of origin_Wild boar']\n",
    "list_haem = ['Haemolysis_a', 'Haemolysis_b']\n",
    "list_subs = [\"K-means_Canis\", \"K-means_Dysgalactiae\", \"K-means_Equisimilis\"]\n",
    "\n",
    "models = {\n",
    "  'LogisticRegression': LogisticRegression(random_state=RANDOM_STATE),\n",
    "  'Ridge' : RidgeClassifier(random_state=RANDOM_STATE),\n",
    "  #'DecisionTree': DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "  #'K-nn': KNeighborsClassifier(),\n",
    "  'RandomForest': RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "  'BernoulliNB': BernoulliNB(),\n",
    "  'GaussianNB': GaussianNB(),\n",
    "  #'NearestCentroid': NearestCentroid(),\n",
    "  'SVC' : SVC(),\n",
    "  'LinearSVC' : LinearSVC(),\n",
    "  'LabelPropagation' : LabelPropagation(),\n",
    "  'LabelSpreading' : LabelSpreading(),\n",
    "  'SGDClassifier' : SGDClassifier()\n",
    "  #'stack' : StackingCVClassifier\n",
    "}\n",
    "\n",
    "models_cluster = [\n",
    "  'K-means',\n",
    "  #'AgglomerativeClustering'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_cluster(X, y, str_df):\n",
    "  pred_cluster = pd.DataFrame()\n",
    "\n",
    "  #Dataframe con risultati metriche per ogni modello\n",
    "  metrics_df_cluster = pd.DataFrame(columns=['Target', 'Dataframe', 'Model',\n",
    "                              'Silhouette', 'Calinski', 'Davies'])\n",
    "\n",
    "  for name in models_cluster:\n",
    "    print(\"Modello \"+name)\n",
    "    model = pickle.load(open('../models/cluster_'+tutti_picchi+str_df+'_'+name+'.pkl', \"rb\"))\n",
    "    y_pred = model.predict(X)\n",
    "    y_pred = pd.DataFrame(y_pred,X.index)\n",
    "    pred_cluster[name] = y_pred\n",
    "  pred_cluster.index = X.index \n",
    "  pred_cluster.to_csv('../new_prediction/cluster_'+str_df+'.csv', index = True)  \n",
    "  display(pred_cluster)\n",
    "  return pred_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIModelApp:\n",
    "\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Streptococcus Subspecies Predictor\")\n",
    "        self.root.resizable(0, 0)\n",
    "\n",
    "        self.frame_path = ttk.Frame(self.root)\n",
    "        self.frame_path.pack()\n",
    "        #frame.title(\"Streptococcus Subspecies Predictor\")\n",
    "        #self.root.resizable(0, 0)\n",
    "\n",
    "        '''try:\n",
    "            # windows only (remove the minimize/maximize button)\n",
    "            self.root.attributes('-toolwindow', True)\n",
    "        except TclError:\n",
    "            print('Not supported on your platform')'''\n",
    "        \n",
    "        '''self.root.columnconfigure(0, weight=4)\n",
    "        self.root.columnconfigure(1, weight=1)\n",
    "        self.file_path = None\n",
    "\n",
    "        # grid layout for the input frame\n",
    "        self.frame.columnconfigure(0, weight=1)\n",
    "        self.frame.columnconfigure(0, weight=3)'''\n",
    "        self.path_frame = ttk.LabelFrame(self.frame_path, text='Posizione File:')\n",
    "        self.path_frame.grid(column=0, row=0)\n",
    "\n",
    "        self.path_entry = ttk.Entry(self.path_frame)\n",
    "        self.path_entry.insert(0, \"C:\\...\\$filename.xlsx \")\n",
    "        self.path_entry.bind(\"<FocusIn>\", lambda e: self.path_entry.delete('0', 'end'))\n",
    "        self.path_entry.grid(column=0, row=0, sticky=\"ew\")\n",
    "\n",
    "        ttk.Button(self.frame_path, text='Carica file Maldi', command=self.load_file).grid(column=1, row=0)\n",
    "    \n",
    "    def create_frame_form(self):\n",
    "        self.feature_vars = [\"Specie animale\", \"Haemolysis\"]\n",
    "        self.target_vars = [\"Sottospecie\", \"Clindamicina\", \"IsaE\"]\n",
    "        self.window = tk.Tk()\n",
    "        self.window.title('Elements table')\n",
    "        style = ttk.Style(self.window)\n",
    "        self.window.tk.call(\"source\", \"forest-dark.tcl\")\n",
    "        style.theme_use(\"forest-dark\")\n",
    "        \n",
    "        self.option_frame = ttk.LabelFrame(self.window, text='Elementi tabella')\n",
    "        self.option_frame.grid(row=0, column=0)\n",
    "\n",
    "        self.picchi_spinbox = ttk.Spinbox(self.option_frame, from_=1, to=10000)\n",
    "        self.picchi_spinbox.insert(0, \"56\")\n",
    "        self.picchi_spinbox.grid(row=0, column=0, padx=5, pady=5, sticky=\"ew\")\n",
    "        \n",
    "        ttk.Label(self.option_frame, text='Features aggiuntive:').grid(column=0, row=1, sticky=\"ew\")\n",
    "        # Match Case checkbox\n",
    "        row = 2\n",
    "        self.feat_case = {}\n",
    "        self.feat_case_check = {}\n",
    "        \n",
    "        for var in self.feature_vars:\n",
    "            self.feat_case[var] = tk.BooleanVar()\n",
    "            self.feat_case_check[var] = ttk.Checkbutton(self.option_frame, text=var, variable=self.feat_case[var])\n",
    "            self.feat_case_check[var].grid(column=0, row=row, sticky='nsew')\n",
    "            \n",
    "            row += 1\n",
    "        \n",
    "        ttk.Label(self.option_frame, text='Target ricercati:').grid(column=1, row=1, sticky=\"ew\")\n",
    "        # Match Case checkbox\n",
    "        row = 2\n",
    "        self.target_case = {}\n",
    "        self.target_case_check = {}\n",
    "        for var in self.target_vars:\n",
    "            self.target_case[var] = tk.BooleanVar()\n",
    "            self.target_case_check[var] = ttk.Checkbutton(self.option_frame, text=var, variable=self.target_case[var])\n",
    "            \n",
    "            self.target_case_check[var].grid(column=1, row=row, sticky='nsew')\n",
    "            row += 1\n",
    "        \n",
    "        self.button_frame = ttk.Frame(self.window)\n",
    "        self.button_frame.grid(row=1, column=0)\n",
    "        self.button_modify = ttk.Button(self.button_frame, text='Modifica tabella', command=self.modify_table).grid(column=0, row=6)\n",
    "        self.button_modify = ttk.Button(self.button_frame, text='Avvia previsione', command=self.predict).grid(column=1, row=6)\n",
    "\n",
    "        for widget in self.option_frame.winfo_children():\n",
    "            widget.grid(padx=5, pady=5)\n",
    "        for widget in self.button_frame.winfo_children():\n",
    "            widget.grid(padx=5, pady=5)\n",
    "\n",
    "        self.preview_table()\n",
    "    \n",
    "    def preview_table(self):\n",
    "        self.window_table = tk.Tk()\n",
    "        self.window_table.geometry(\"600x400\")\n",
    "        self.window_table.title('Preview Table')\n",
    "        style = ttk.Style(self.window_table)\n",
    "        self.window_table.tk.call(\"source\", \"forest-dark.tcl\")\n",
    "        style.theme_use(\"forest-dark\")\n",
    "\n",
    "        self.treeFrame = ttk.Frame(self.window_table)\n",
    "        self.treeFrame.grid(row=0, column=0)\n",
    "        #self.treeScroll = ttk.Scrollbar(self.treeFrame)\n",
    "        #self.treeScroll.pack(side=\"left\", fill=\"y\")\n",
    "        self.treeScrollX = ttk.Scrollbar(self.treeFrame, orient='horizontal')\n",
    "        self.treeScrollX.pack(side=\"bottom\", fill=\"x\")\n",
    "\n",
    "        self.workbook = openpyxl.load_workbook(self.file_path)\n",
    "        self.sheet = self.workbook.active\n",
    "\n",
    "        self.list_values = list(self.sheet.values)\n",
    "        print(self.list_values)\n",
    "        cols = self.list_values[0]\n",
    "        \n",
    "        self.treeview = ttk.Treeview(self.treeFrame, show=\"headings\", columns=cols,\n",
    "                                 xscrollcommand=self.treeScrollX.set)\n",
    "        self.treeview.column(\"ID Strain\", width=70)\n",
    "        self.treeview.column(\"Animal species of origin\", width=150)\n",
    "        self.treeview.column(\"Haemolysis\", width=70)\n",
    "        self.treeScrollX.config(command=self.treeview.xview)\n",
    "        self.treeview.pack()\n",
    "        \n",
    "        #self.treeScroll.config(command=self.treeview.yview)\n",
    "        \n",
    "\n",
    "        for col_name in cols:\n",
    "            self.treeview.heading(col_name, text = col_name)\n",
    "        \n",
    "        for value_tuple in self.list_values[1:]:\n",
    "            self.treeview.insert('',tk.END, values=value_tuple)\n",
    "\n",
    "    def load_file(self):\n",
    "        self.file_path = filedialog.askopenfilename(filetypes=[(\"Xlsx File\", \"*.xlsx\")])\n",
    "        self.path_entry.insert(0, self.file_path)\n",
    "        self.create_frame_form()\n",
    "\n",
    "    def modify_table():\n",
    "        return 0\n",
    "    \n",
    "    def load_data(self, features, targets, n):\n",
    "        self.df = pd.read_excel(self.file_path,\n",
    "                             index_col='ID Strain')\n",
    "        display(self.df)\n",
    "        maldi = self.df.iloc[:,start:start+n]\n",
    "        maldi.fillna(0, inplace=True)\n",
    "        maldi = maldi.replace(',', '.', regex=True)\n",
    "        columns = maldi.columns\n",
    "        for column in columns:\n",
    "            maldi[column] = maldi[column].astype(float)\n",
    "        display(maldi)\n",
    "        \n",
    "        col = maldi.columns.to_list()\n",
    "        '''col = [i.replace(',', '.') for i in col]\n",
    "        col = [int(float(i)) for i in col]'''\n",
    "        col = [int(i) for i in col]\n",
    "        maldi.columns = col\n",
    "        print(col\n",
    "        )\n",
    "        for i in range(2000,16500):\n",
    "            if i not in maldi.columns:\n",
    "                maldi[i] = 0\n",
    "        maldi = maldi.reindex(sorted(maldi.columns), axis=1)\n",
    "        maldi = maldi.fillna(0)\n",
    "        \n",
    "        maldi.columns = maldi.columns.astype(str)\n",
    "        data = maldi\n",
    "        \n",
    "        for feature in features:\n",
    "            if feature == 'Specie animale':\n",
    "                animals = df.iloc[:,0]\n",
    "                #display(animals)\n",
    "                animals_dummies = pd.DataFrame.from_dict(pd.get_dummies(animals))\n",
    "                if ('Specie animale' and 'Haemolysis') in features:\n",
    "                    str_df = 'agg'\n",
    "                    columns = animals_dummies.columns\n",
    "                    for column in columns:\n",
    "                        animals_dummies.rename(columns = {column : 'Animal species of origin_'+column}, inplace=True)\n",
    "                    missing_cols_animals = set(list_animals_agg) - set(animals_dummies.columns)\n",
    "                    # Add a missing column in test set with default value equal to 0\n",
    "                    for c in missing_cols_animals:\n",
    "                        animals_dummies[str(c)] = 0\n",
    "                    # Ensure the order of column in the test set is in the same order than in train set\n",
    "                    animals_dummies = animals_dummies[list_animals_agg]\n",
    "                else:\n",
    "                    str_df = 'animals'\n",
    "                    missing_cols_animals = set(list_animals) - set(animals_dummies.columns)\n",
    "                    # Add a missing column in test set with default value equal to 0\n",
    "                    for c in missing_cols_animals:\n",
    "                        animals_dummies[str(c)] = 0\n",
    "                    # Ensure the order of column in the test set is in the same order than in train set\n",
    "                    animals_dummies = animals_dummies[list_animals]\n",
    "                data = pd.concat([data,animals_dummies], axis=1)\n",
    "            if feature == 'Haemolysis':\n",
    "                haem = df.iloc[:,1]\n",
    "                #display(haem)\n",
    "                if 'Specie animale' not in features:\n",
    "                    str_df = 'hae'\n",
    "                haem_dummies = pd.DataFrame.from_dict(pd.get_dummies(haem))\n",
    "                haem_dummies.rename(columns = {'a' : 'Haemolysis_a', 'b' : 'Haemolysis_b'}, inplace=True)\n",
    "                missing_cols_haem = set(list_haem) - set(haem_dummies.columns)\n",
    "                for c in missing_cols_haem:\n",
    "                    haem_dummies[str(c)] = 0\n",
    "                haem_dummies = haem_dummies[list_haem]\n",
    "                data = pd.concat([data,haem_dummies], axis=1)\n",
    "    \n",
    "        display(data)\n",
    "        \n",
    "        targets_col = 'Sottospecie'\n",
    "        for target in targets:\n",
    "            if target == 'Sottospecie':\n",
    "                targets_col.append('subspecies')\n",
    "            else:\n",
    "                targets_col.append(target)\n",
    "        print(targets_col)\n",
    "        str_df = ''\n",
    "        str_df = str_df+'_npicchi306'\n",
    "        return data, str_df, targets_col\n",
    "\n",
    "    def predict(self):\n",
    "        if self.file_path is None:\n",
    "            messagebox.showerror(\"Errore\", \"Carica prima un file CSV!\")\n",
    "            return\n",
    "\n",
    "        try:\n",
    "            num_picchi = int(self.picchi_spinbox.get())\n",
    "        except ValueError:\n",
    "            messagebox.showerror(\"Errore\", \"Inserisci un numero valido per i picchi!\")\n",
    "            return\n",
    "        print(num_picchi)\n",
    "        \n",
    "        features = list()\n",
    "        targets = list()\n",
    "        for var, checkbox in self.feat_case.items():\n",
    "            print(checkbox.get())\n",
    "            if checkbox.get() == True:\n",
    "                features = features.append(var)\n",
    "        for var, checkbox in self.target_case.items():\n",
    "            if checkbox.get() == True:\n",
    "                targets = features.append(var)\n",
    "\n",
    "        print(features)\n",
    "        print(targets)\n",
    "        data, str_df, targets_col = self.load_data(features, targets, num_picchi)\n",
    "        print(str_df)\n",
    "        print(data.columns)\n",
    "        #data = pd.read_csv(self.file_path)\n",
    "        if 'subspecies' in targets_col:\n",
    "            y = 'subspecies'\n",
    "            pred_cluster = prediction_cluster(data, y, str_df)\n",
    "            data_cluster = pd.concat([data, pred_cluster], axis = 1)\n",
    "        X = data\n",
    "        prediction = {}\n",
    "        for target in targets_col:\n",
    "            prediction[target] = pd.DataFrame(index = X.index)\n",
    "            '''if target == 'subspecies':\n",
    "                X = data_cluster\n",
    "            else:\n",
    "                x = data'''\n",
    "            for name in models:\n",
    "                #print(\"Modello \"+name)\n",
    "                path = '../models/models_base/'+name+'_'+tutti_picchi+reduction+scaled+scaler+target+'_'+str_df+'.pkl'\n",
    "                print(path)\n",
    "                model = pickle.load(open(path, 'rb'))\n",
    "\n",
    "                y_pred = model.predict(X)\n",
    "                prediction[target][name] = y_pred\n",
    "            prediction[target].index = X.index\n",
    "            \n",
    "            #Aggiunge i valori del target nei dizionari\n",
    "            prediction[target].to_csv('../new_prediction/'+target+tutti_picchi+reduction+scaled+scaler+'_basemodel_'+name+'_'+str_df+'.csv', index = True)\n",
    "            display(prediction[target])\n",
    "        \n",
    "        prediction = pd.DataFrame(index = X.index)\n",
    "        for target in targets_col:\n",
    "            model = pickle.load(open('../models/stack_'+tutti_picchi+reduction+scaled+scaler+target+'_'+str_df+'.pkl', \"rb\"))\n",
    "            print(model)\n",
    "            y_pred = model.predict(X)\n",
    "            display(y_pred)\n",
    "            prediction[target] = y_pred\n",
    "            if (target == 'Clindamicina'):\n",
    "                prediction[target] = prediction[target].map(map_target_antibiotici_inv)\n",
    "            if (target == 'subspecies'):\n",
    "                prediction[target] = prediction[target].map(map_target_inv)\n",
    "        prediction.to_csv('../new_prediction/stack_'+tutti_picchi+reduction+scaled+scaler+str_df+'.csv', index = True)\n",
    "        display(prediction)\n",
    "        \n",
    "        # Mostra i risultati della previsione in una nuova finestra\n",
    "        result_window = tk.Toplevel(self.root)\n",
    "        result_window.title(\"Risultato previsione\")\n",
    "        result_window.geometry(\"300x100\")\n",
    "\n",
    "        for target in targets:\n",
    "            result_label = tk.Label(result_window, text=f\"Risultato {target} previsione: {prediction[target]}\")\n",
    "            result_label.pack(pady=20)\n",
    "\n",
    "        # Pulsante per chiudere la finestra\n",
    "        close_button = tk.Button(result_window, text=\"Esci\", command=result_window.destroy)\n",
    "        close_button.pack()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    style = ttk.Style(root)\n",
    "    root.tk.call(\"source\", \"forest-dark.tcl\")\n",
    "    style.theme_use(\"forest-dark\")\n",
    "    app = AIModelApp(root)\n",
    "    root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
