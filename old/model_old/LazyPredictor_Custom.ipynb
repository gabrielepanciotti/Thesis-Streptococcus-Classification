{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import time\n",
    "import warnings\n",
    "import xgboost\n",
    "#import catboost\n",
    "import lightgbm\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer, MissingIndicator\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.utils import all_estimators\n",
    "from sklearn.base import RegressorMixin\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    precision_score, \n",
    "    recall_score,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    f1_score,\n",
    "    r2_score,\n",
    "    mean_squared_error,\n",
    "    classification_report\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    cross_val_score,\n",
    "    StratifiedKFold,\n",
    "    RandomizedSearchCV,\n",
    "    GridSearchCV,\n",
    "    learning_curve,\n",
    "    validation_curve\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from scipy import stats\n",
    "from pca import pca\n",
    "from IPython.display import display\n",
    "import dataframe_image as dfi\n",
    "\n",
    "from src.visualization import feature_importances_plot\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.precision\", 2)\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.2f\" % x)\n",
    "\n",
    "removed_classifiers = [\n",
    "    \"ClassifierChain\",\n",
    "    \"ComplementNB\",\n",
    "    \"GradientBoostingClassifier\",\n",
    "    \"GaussianProcessClassifier\",\n",
    "    \"HistGradientBoostingClassifier\",\n",
    "    \"MLPClassifier\",\n",
    "    \"LogisticRegressionCV\", \n",
    "    \"MultiOutputClassifier\", \n",
    "    \"MultinomialNB\", \n",
    "    \"OneVsOneClassifier\",\n",
    "    \"OneVsRestClassifier\",\n",
    "    \"OutputCodeClassifier\",\n",
    "    \"RadiusNeighborsClassifier\",\n",
    "    \"VotingClassifier\",\n",
    "]\n",
    "\n",
    "removed_regressors = [\n",
    "    \"TheilSenRegressor\",\n",
    "    \"ARDRegression\", \n",
    "    \"CCA\", \n",
    "    \"IsotonicRegression\", \n",
    "    \"StackingRegressor\",\n",
    "    \"MultiOutputRegressor\", \n",
    "    \"MultiTaskElasticNet\", \n",
    "    \"MultiTaskElasticNetCV\", \n",
    "    \"MultiTaskLasso\", \n",
    "    \"MultiTaskLassoCV\", \n",
    "    \"PLSCanonical\", \n",
    "    \"PLSRegression\", \n",
    "    \"RadiusNeighborsRegressor\", \n",
    "    \"RegressorChain\", \n",
    "    \"VotingRegressor\", \n",
    "]\n",
    "\n",
    "CLASSIFIERS = [\n",
    "    est\n",
    "    for est in all_estimators()\n",
    "    if (issubclass(est[1], ClassifierMixin) and (est[0] not in removed_classifiers))\n",
    "]\n",
    "\n",
    "REGRESSORS = [\n",
    "    est\n",
    "    for est in all_estimators()\n",
    "    if (issubclass(est[1], RegressorMixin) and (est[0] not in removed_regressors))\n",
    "]\n",
    "\n",
    "REGRESSORS.append((\"XGBRegressor\", xgboost.XGBRegressor))\n",
    "REGRESSORS.append((\"LGBMRegressor\", lightgbm.LGBMRegressor))\n",
    "# REGRESSORS.append(('CatBoostRegressor',catboost.CatBoostRegressor))\n",
    "\n",
    "CLASSIFIERS.append((\"XGBClassifier\", xgboost.XGBClassifier))\n",
    "CLASSIFIERS.append((\"LGBMClassifier\", lightgbm.LGBMClassifier))\n",
    "# CLASSIFIERS.append(('CatBoostClassifier',catboost.CatBoostClassifier))\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"constant\")), (\"scaler\", StandardScaler())]\n",
    ")\n",
    "\n",
    "categorical_transformer_low = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "        (\"encoding\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer_high = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "        # 'OrdianlEncoder' Raise a ValueError when encounters an unknown value. Check https://github.com/scikit-learn/scikit-learn/pull/13423\n",
    "        (\"encoding\", OrdinalEncoder()),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "N_JOBS = -1\n",
    "class_names = [\"Canis\", \"Dysg. Equisimilis\", \"Dysg. Dysgalactiae\"]\n",
    "\n",
    "map_target = {\n",
    "    \"Streptococcus canis\": 0,\n",
    "    \"Streptococcus dysgalactiae subsp. equisimilis\": 1,\n",
    "    \"Streptococcus dysgalactiae subsp. dysgalactiae\": 2\n",
    "}\n",
    "\n",
    "map_target_inv = {\n",
    "    0: \"Strept. canis\",\n",
    "    1: \"Strept. dysg. equisimilis\",\n",
    "    2: \"Strept. dysg. dysgalactiae\"\n",
    "}\n",
    "\n",
    "map_target_antibiotici = {\n",
    "    \"S\" : 1,\n",
    "    \"NS\" : 0\n",
    "}\n",
    "start = 9\n",
    "n_antibiotici = 9\n",
    "n_geni = 27\n",
    "n_virulenza = 18\n",
    "#n_picchi = ['46','306']\n",
    "n_picchi = ['46']\n",
    "N_BEST = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = [0,1]\n",
    "# Hyperparameter tuning using RandomizedSearchCV\n",
    "param_grid = {'LogisticRegression': {'C': np.logspace(-4, 4, 20), \n",
    "                                    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "                                    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "                                    'fit_intercept': [True, False],\n",
    "                                    'intercept_scaling': [0.5, 1, 2],\n",
    "                                    'class_weight': [None, 'balanced']},\n",
    "              'RidgeClassifier' : {'alpha': np.logspace(-5, 5, 100)},\n",
    "              'DecisionTreeClassifier': {'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "                                        'splitter': ['best', 'random'],\n",
    "                                        'max_depth': [2*n for n in range(1,10)],\n",
    "                                        'max_features': ['auto', 'sqrt', 'log2'],\n",
    "                                        'min_samples_leaf': [1, 2, 4],\n",
    "                                        'min_samples_split': [2, 5, 10],\n",
    "                                        'class_weight': [None, 'balanced']},\n",
    "              'KNeighborsClassifier': {'n_neighbors': list(range(1, 20)),\n",
    "                                        'weights': ['uniform', 'distance'],\n",
    "                                        'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "                                        'p': [1,2]},\n",
    "              'RandomForestClassifier': {'n_estimators': range(10, 100), \n",
    "                                        'max_features': ['auto', 'sqrt', 'log2'],\n",
    "                                        'max_depth': [2*n for n in range(1,10)],\n",
    "                                        'min_samples_split': range(2, 15), \n",
    "                                        'class_weight': [None, 'balanced'], \n",
    "                                        'criterion': ['gini', 'entropy', 'log_loss']},\n",
    "              'BernoulliNB': {'alpha': [0.01, 0.1, 0.5, 1.0, 10.0],\n",
    "                            'fit_prior': [True, False],\n",
    "                            'class_prior': [None, [0.1,]* len(n_classes)],\n",
    "                            'binarize': [None, -5, 0.0, 5, 10.0]\n",
    "                            },\n",
    "              'GaussianNB': {'var_smoothing': np.logspace(0,-9, num=20)},\n",
    "              'NearestCentroid':  {'shrink_threshold': np.logspace(0, 1, 20),\n",
    "                                   'metric': ['euclidean', 'manhattan']},\n",
    "              'SVC': {'C': np.logspace(-3, 3, 10),\n",
    "                    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "                    'degree': range(2,5),\n",
    "                    'gamma': np.logspace(-3, 1, 10)},\n",
    "              'SGDClassifier':{'loss' : ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron'],\n",
    "                            'penalty' : ['l1', 'l2', 'elasticnet'],\n",
    "                            'alpha' : [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "                            'learning_rate' : ['constant', 'optimal', 'invscaling', 'adaptive'],\n",
    "                            'class_weight' : [{1:0.5, 0:0.5}, {1:0.4, 0:0.6}, {1:0.6, 0:0.4}, {1:0.7, 0:0.3}],\n",
    "                            'eta0' : [1, 10, 100]}\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_card_split(df, cols, n=11):\n",
    "    \"\"\"\n",
    "    Splits categorical columns into 2 lists based on cardinality (i.e # of unique values)\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : Pandas DataFrame\n",
    "        DataFrame from which the cardinality of the columns is calculated.\n",
    "    cols : list-like\n",
    "        Categorical columns to list\n",
    "    n : int, optional (default=11)\n",
    "        The value of 'n' will be used to split columns.\n",
    "    Returns\n",
    "    -------\n",
    "    card_low : list-like\n",
    "        Columns with cardinality < n\n",
    "    card_high : list-like\n",
    "        Columns with cardinality >= n\n",
    "    \"\"\"\n",
    "    cond = df[cols].nunique() > n\n",
    "    card_high = cols[cond]\n",
    "    card_low = cols[~cond]\n",
    "    return card_low, card_high\n",
    "\n",
    "def makeTuning(model, model_name, X_train, y_train):\n",
    "    #print(model_name)\n",
    "    #print(model)\n",
    "    params = param_grid.get(model_name)\n",
    "\n",
    "    if params != None:\n",
    "        rs = GridSearchCV(estimator=model(), param_grid=params,\n",
    "                            scoring=\"accuracy\", n_jobs=-1, cv=skfold, verbose=0)\n",
    "        rs.fit(X_train, y_train)\n",
    "        params = rs.best_params_\n",
    "        model = rs.best_estimator_\n",
    "        cv_best = rs.best_score_\n",
    "        model_name = model_name+'_Best'\n",
    "\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LazyClassifierCustom:\n",
    "    \"\"\"\n",
    "    This module helps in fitting to all the classification algorithms that are available in Scikit-learn\n",
    "    Parameters\n",
    "    ----------\n",
    "    verbose : int, optional (default=0)\n",
    "        For the liblinear and lbfgs solvers set verbose to any positive\n",
    "        number for verbosity.\n",
    "    ignore_warnings : bool, optional (default=True)\n",
    "        When set to True, the warning related to algorigms that are not able to run are ignored.\n",
    "    custom_metric : function, optional (default=None)\n",
    "        When function is provided, models are evaluated based on the custom evaluation metric provided.\n",
    "    prediction : bool, optional (default=False)\n",
    "        When set to True, the predictions of all the models models are returned as dataframe.\n",
    "    classifiers : list, optional (default=\"all\")\n",
    "        When function is provided, trains the chosen classifier(s).\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        verbose=0,\n",
    "        ignore_warnings=True,\n",
    "        custom_metric=None,\n",
    "        predictions=False,\n",
    "        random_state=42,\n",
    "        classifiers=\"all\",\n",
    "    ):\n",
    "        self.verbose = verbose\n",
    "        self.ignore_warnings = ignore_warnings\n",
    "        self.custom_metric = custom_metric\n",
    "        self.predictions = predictions\n",
    "        self.models = {}\n",
    "        self.random_state = random_state\n",
    "        self.classifiers = classifiers\n",
    "\n",
    "    def fit(self, X_train, X_test, y_train, y_test):\n",
    "        \"\"\"Fit Classification algorithms to X_train and y_train, predict and score on X_test, y_test.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : array-like,\n",
    "            Training vectors, where rows is the number of samples\n",
    "            and columns is the number of features.\n",
    "        X_test : array-like,\n",
    "            Testing vectors, where rows is the number of samples\n",
    "            and columns is the number of features.\n",
    "        y_train : array-like,\n",
    "            Training vectors, where rows is the number of samples\n",
    "            and columns is the number of features.\n",
    "        y_test : array-like,\n",
    "            Testing vectors, where rows is the number of samples\n",
    "            and columns is the number of features.\n",
    "        Returns\n",
    "        -------\n",
    "        scores : Pandas DataFrame\n",
    "            Returns metrics of all the models in a Pandas DataFrame.\n",
    "        predictions : Pandas DataFrame\n",
    "            Returns predictions of all the models in a Pandas DataFrame.\n",
    "        \"\"\"\n",
    "        Accuracy = []\n",
    "        B_Accuracy = []\n",
    "        ROC_AUC = []\n",
    "        F1 = []\n",
    "        names = []\n",
    "        TIME = []\n",
    "        predictions = {}\n",
    "\n",
    "        if self.custom_metric is not None:\n",
    "            CUSTOM_METRIC = []\n",
    "\n",
    "        if isinstance(X_train, np.ndarray):\n",
    "            X_train = pd.DataFrame(X_train)\n",
    "            X_test = pd.DataFrame(X_test)\n",
    "\n",
    "        numeric_features = X_train.select_dtypes(include=[np.number]).columns\n",
    "        categorical_features = X_train.select_dtypes(include=[\"object\"]).columns\n",
    "\n",
    "        categorical_low, categorical_high = get_card_split(\n",
    "            X_train, categorical_features\n",
    "        )\n",
    "\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                (\"numeric\", numeric_transformer, numeric_features),\n",
    "                (\"categorical_low\", categorical_transformer_low, categorical_low),\n",
    "                (\"categorical_high\", categorical_transformer_high, categorical_high),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        if self.classifiers == \"all\":\n",
    "            self.classifiers = CLASSIFIERS\n",
    "        else:\n",
    "            try:\n",
    "                temp_list = []\n",
    "                for classifier in self.classifiers:\n",
    "                    full_name = (classifier.__name__, classifier)\n",
    "                    temp_list.append(full_name)\n",
    "                self.classifiers = temp_list\n",
    "            except Exception as exception:\n",
    "                print(exception)\n",
    "                print(\"Invalid Classifier(s)\")\n",
    "\n",
    "        for name, model in tqdm(self.classifiers):\n",
    "            start = time.time()\n",
    "            n_classes = np.unique(y_train)\n",
    "            parametri = makeTuning(model, name, X_train, y_train)\n",
    "            if parametri != None:\n",
    "                print(model().get_params())\n",
    "            try:\n",
    "                if \"random_state\" in model().get_params().keys():\n",
    "                    pipe = Pipeline(\n",
    "                        steps=[\n",
    "                            (\"preprocessor\", preprocessor),\n",
    "                            (\"classifier\", model(random_state=self.random_state)),\n",
    "                        ]\n",
    "                    )\n",
    "                else:\n",
    "                    pipe = Pipeline(\n",
    "                        steps=[(\"preprocessor\", preprocessor), (\"classifier\", model())]\n",
    "                    )\n",
    "                \n",
    "                pipe.fit(X_train, y_train)\n",
    "                self.models[name] = pipe\n",
    "                y_pred = pipe.predict(X_test)\n",
    "                accuracy = accuracy_score(y_test, y_pred, normalize=True)\n",
    "                b_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "                f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "                try:\n",
    "                    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "                except Exception as exception:\n",
    "                    roc_auc = None\n",
    "                    if self.ignore_warnings is False:\n",
    "                        print(\"ROC AUC couldn't be calculated for \" + name)\n",
    "                        print(exception)\n",
    "                names.append(name)\n",
    "                Accuracy.append(accuracy)\n",
    "                B_Accuracy.append(b_accuracy)\n",
    "                ROC_AUC.append(roc_auc)\n",
    "                F1.append(f1)\n",
    "                TIME.append(time.time() - start)\n",
    "                if self.custom_metric is not None:\n",
    "                    custom_metric = self.custom_metric(y_test, y_pred)\n",
    "                    CUSTOM_METRIC.append(custom_metric)\n",
    "                if self.verbose > 0:\n",
    "                    if self.custom_metric is not None:\n",
    "                        print(\n",
    "                            {\n",
    "                                \"Model\": name,\n",
    "                                \"Accuracy\": accuracy,\n",
    "                                \"Balanced Accuracy\": b_accuracy,\n",
    "                                \"ROC AUC\": roc_auc,\n",
    "                                \"F1 Score\": f1,\n",
    "                                self.custom_metric.__name__: custom_metric,\n",
    "                                \"Time taken\": time.time() - start,\n",
    "                            }\n",
    "                        )\n",
    "                    else:\n",
    "                        print(\n",
    "                            {\n",
    "                                \"Model\": name,\n",
    "                                \"Accuracy\": accuracy,\n",
    "                                \"Balanced Accuracy\": b_accuracy,\n",
    "                                \"ROC AUC\": roc_auc,\n",
    "                                \"F1 Score\": f1,\n",
    "                                \"Time taken\": time.time() - start,\n",
    "                            }\n",
    "                        )\n",
    "                if self.predictions:\n",
    "                    predictions[name] = y_pred\n",
    "                \n",
    "                if parametri != None:\n",
    "                    name = name+'_Best'\n",
    "                    pipe['classifier'].set_params(**parametri)\n",
    "                    parametri = pipe['classifier'].get_params()\n",
    "                    print(parametri)\n",
    "                    pipe.fit(X_train, y_train)\n",
    "                    self.models[name] = pipe\n",
    "                    y_pred = pipe.predict(X_test)\n",
    "                    accuracy = accuracy_score(y_test, y_pred, normalize=True)\n",
    "                    b_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "                    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "                    try:\n",
    "                        roc_auc = roc_auc_score(y_test, y_pred)\n",
    "                    except Exception as exception:\n",
    "                        roc_auc = None\n",
    "                        if self.ignore_warnings is False:\n",
    "                            print(\"ROC AUC couldn't be calculated for \" + name)\n",
    "                            print(exception)\n",
    "                    names.append(name)\n",
    "                    Accuracy.append(accuracy)\n",
    "                    B_Accuracy.append(b_accuracy)\n",
    "                    ROC_AUC.append(roc_auc)\n",
    "                    F1.append(f1)\n",
    "                    TIME.append(time.time() - start)\n",
    "                    if self.custom_metric is not None:\n",
    "                        custom_metric = self.custom_metric(y_test, y_pred)\n",
    "                        CUSTOM_METRIC.append(custom_metric)\n",
    "                    if self.verbose > 0:\n",
    "                        if self.custom_metric is not None:\n",
    "                            print(\n",
    "                                {\n",
    "                                    \"Model\": name,\n",
    "                                    \"Accuracy\": accuracy,\n",
    "                                    \"Balanced Accuracy\": b_accuracy,\n",
    "                                    \"ROC AUC\": roc_auc,\n",
    "                                    \"F1 Score\": f1,\n",
    "                                    self.custom_metric.__name__: custom_metric,\n",
    "                                    \"Time taken\": time.time() - start,\n",
    "                                }\n",
    "                            )\n",
    "                        else:\n",
    "                            print(\n",
    "                                {\n",
    "                                    \"Model\": name,\n",
    "                                    \"Accuracy\": accuracy,\n",
    "                                    \"Balanced Accuracy\": b_accuracy,\n",
    "                                    \"ROC AUC\": roc_auc,\n",
    "                                    \"F1 Score\": f1,\n",
    "                                    \"Time taken\": time.time() - start,\n",
    "                                }\n",
    "                            )\n",
    "                    if self.predictions:\n",
    "                        predictions[name] = y_pred\n",
    "                    \n",
    "            except Exception as exception:\n",
    "                if self.ignore_warnings is False:\n",
    "                    print(name + \" model failed to execute\")\n",
    "                    print(exception)\n",
    "        if self.custom_metric is None:\n",
    "            scores = pd.DataFrame(\n",
    "                {\n",
    "                    \"Model\": names,\n",
    "                    \"Accuracy\": Accuracy,\n",
    "                    \"Balanced Accuracy\": B_Accuracy,\n",
    "                    \"ROC AUC\": ROC_AUC,\n",
    "                    \"F1 Score\": F1,\n",
    "                    \"Time Taken\": TIME,\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            scores = pd.DataFrame(\n",
    "                {\n",
    "                    \"Model\": names,\n",
    "                    \"Accuracy\": Accuracy,\n",
    "                    \"Balanced Accuracy\": B_Accuracy,\n",
    "                    \"ROC AUC\": ROC_AUC,\n",
    "                    \"F1 Score\": F1,\n",
    "                    self.custom_metric.__name__: CUSTOM_METRIC,\n",
    "                    \"Time Taken\": TIME,\n",
    "                }\n",
    "            )\n",
    "        scores = scores.sort_values(by=\"Balanced Accuracy\", ascending=False).set_index(\n",
    "            \"Model\"\n",
    "        )\n",
    "        \n",
    "        if self.predictions:\n",
    "            predictions_df = pd.DataFrame.from_dict(predictions)\n",
    "        return scores, predictions_df if self.predictions is True else scores\n",
    "\n",
    "    def provide_models(self, X_train, X_test, y_train, y_test):\n",
    "        \"\"\"\n",
    "        This function returns all the model objects trained in fit function.\n",
    "        If fit is not called already, then we call fit and then return the models.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X_train : array-like,\n",
    "            Training vectors, where rows is the number of samples\n",
    "            and columns is the number of features.\n",
    "        X_test : array-like,\n",
    "            Testing vectors, where rows is the number of samples\n",
    "            and columns is the number of features.\n",
    "        y_train : array-like,\n",
    "            Training vectors, where rows is the number of samples\n",
    "            and columns is the number of features.\n",
    "        y_test : array-like,\n",
    "            Testing vectors, where rows is the number of samples\n",
    "            and columns is the number of features.\n",
    "        Returns\n",
    "        -------\n",
    "        models: dict-object,\n",
    "            Returns a dictionary with each model pipeline as value \n",
    "            with key as name of models.\n",
    "        \"\"\"\n",
    "        if len(self.models.keys()) == 0:\n",
    "            self.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "        return self.models\n",
    "\n",
    "\n",
    "def adjusted_rsquared(r2, n, p):\n",
    "    return 1 - (1 - r2) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "Classification = LazyClassifierCustom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeDictBest(models, modelli, n_best = 5):\n",
    "    for i in range(n_best):\n",
    "        best = models.index[i]\n",
    "        score = modelli.get(best)\n",
    "        if score != None:\n",
    "            modelli[best] = score + (n_best-i)\n",
    "        else:\n",
    "            modelli[best] = (n_best-i)\n",
    "    return modelli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATAFRAME CON 46 PICCHI\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2223,140967</th>\n",
       "      <th>2241,073989</th>\n",
       "      <th>2262,75751</th>\n",
       "      <th>2679,802856</th>\n",
       "      <th>2978,296408</th>\n",
       "      <th>3159,441237</th>\n",
       "      <th>3354,28405</th>\n",
       "      <th>3364,608472</th>\n",
       "      <th>3397,909861</th>\n",
       "      <th>3418,174965</th>\n",
       "      <th>...</th>\n",
       "      <th>9030,351844</th>\n",
       "      <th>9073,208159</th>\n",
       "      <th>9487,183195</th>\n",
       "      <th>10103,20284</th>\n",
       "      <th>10400,80576</th>\n",
       "      <th>10491,16654</th>\n",
       "      <th>10930,54833</th>\n",
       "      <th>13276,73249</th>\n",
       "      <th>14943,03835</th>\n",
       "      <th>15048,89449</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID Strain</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>V13</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V142</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V151</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V160</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V161</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V800</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V82</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V90</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V91</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V95</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           2223,140967  2241,073989  2262,75751  2679,802856  2978,296408  \\\n",
       "ID Strain                                                                   \n",
       "V13               0.00         0.00        0.00         0.00         0.00   \n",
       "V142              0.00         0.00        0.00         0.00         0.00   \n",
       "V151              0.00         0.00        0.00         0.00         0.00   \n",
       "V160              0.00         0.00        0.00         0.00         0.00   \n",
       "V161              0.00         0.00        0.00         0.00         0.00   \n",
       "...                ...          ...         ...          ...          ...   \n",
       "V800              0.00         0.00        0.00         0.00         0.00   \n",
       "V82               0.00         0.00        0.00         0.00         0.00   \n",
       "V90               0.00         0.00        0.00         0.00         0.00   \n",
       "V91               0.00         0.00        0.00         0.00         0.00   \n",
       "V95               0.00         0.00        0.00         0.00         0.00   \n",
       "\n",
       "           3159,441237  3354,28405  3364,608472  3397,909861  3418,174965  \\\n",
       "ID Strain                                                                   \n",
       "V13               0.00        0.00         0.00         0.00         0.00   \n",
       "V142              0.00        0.00         0.00         0.00         0.00   \n",
       "V151              0.00        0.00         0.00         0.00         0.00   \n",
       "V160              0.00        0.00         0.00         0.00         0.00   \n",
       "V161              0.00        0.00         0.00         0.00         0.00   \n",
       "...                ...         ...          ...          ...          ...   \n",
       "V800              0.00        0.00         0.00         0.00         0.00   \n",
       "V82               0.00        0.00         0.00         0.00         0.00   \n",
       "V90               0.00        0.00         0.00         0.00         0.00   \n",
       "V91               0.00        0.00         0.00         0.00         0.00   \n",
       "V95               0.00        0.00         0.00         0.00         0.00   \n",
       "\n",
       "           ...  9030,351844  9073,208159  9487,183195  10103,20284  \\\n",
       "ID Strain  ...                                                       \n",
       "V13        ...         0.00         0.00         0.00         0.00   \n",
       "V142       ...         0.00         0.00         0.00         0.00   \n",
       "V151       ...         0.00         0.00         0.00         0.00   \n",
       "V160       ...         0.00         0.00         0.00         0.00   \n",
       "V161       ...         0.00         0.00         0.00         0.00   \n",
       "...        ...          ...          ...          ...          ...   \n",
       "V800       ...         0.00         0.00         0.00         0.00   \n",
       "V82        ...         0.00         0.00         0.00         0.00   \n",
       "V90        ...         0.00         0.00         0.00         0.00   \n",
       "V91        ...         0.00         0.00         0.00         0.00   \n",
       "V95        ...         0.00         0.00         0.00         0.00   \n",
       "\n",
       "           10400,80576  10491,16654  10930,54833  13276,73249  14943,03835  \\\n",
       "ID Strain                                                                    \n",
       "V13               0.00         0.00         0.00         0.00         0.00   \n",
       "V142              0.00         0.00         0.00         0.00         0.00   \n",
       "V151              0.00         0.00         0.00         0.00         0.00   \n",
       "V160              0.00         0.00         0.00         0.00         0.00   \n",
       "V161              0.00         0.00         0.00         0.00         0.00   \n",
       "...                ...          ...          ...          ...          ...   \n",
       "V800              0.00         0.00         0.00         0.00         0.00   \n",
       "V82               0.00         0.00         0.00         0.00         0.00   \n",
       "V90               0.00         0.00         0.00         0.00         0.00   \n",
       "V91               0.00         0.00         0.00         0.00         0.00   \n",
       "V95               0.00         0.00         0.00         0.00         0.00   \n",
       "\n",
       "           15048,89449  \n",
       "ID Strain               \n",
       "V13               0.00  \n",
       "V142              0.00  \n",
       "V151              0.00  \n",
       "V160              0.00  \n",
       "V161              0.00  \n",
       "...                ...  \n",
       "V800              0.00  \n",
       "V82               0.00  \n",
       "V90               0.00  \n",
       "V91               0.00  \n",
       "V95               0.00  \n",
       "\n",
       "[154 rows x 46 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fbp54 : 0.0\n",
      "gbs0630 : 0.9935064935064936\n",
      "gbs0631 : 0.9935064935064936\n",
      "gbs0632 : 0.9935064935064936\n",
      "hasC : 0.0\n",
      "lmb : 0.9935064935064936\n",
      "mf2 : 0.961038961038961\n",
      "mf3 : 0.6753246753246753\n",
      "scpA : 0.9935064935064936\n",
      "sda : 0.8766233766233766\n",
      "ska : 0.9935064935064936\n",
      "slo : 0.9935064935064936\n",
      "smeZ : 0.9935064935064936\n",
      "spec : 0.974025974025974\n",
      "speg : 0.9090909090909091\n",
      "spek : 0.961038961038961\n",
      "spel : 0.974025974025974\n",
      "spem : 0.948051948051948\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mf3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID Strain</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>V13</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V142</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V151</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V160</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V161</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V800</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V82</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V90</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V91</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V95</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>154 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           mf3\n",
       "ID Strain     \n",
       "V13          0\n",
       "V142         1\n",
       "V151         0\n",
       "V160         0\n",
       "V161         1\n",
       "...        ...\n",
       "V800         0\n",
       "V82          1\n",
       "V90          0\n",
       "V91          1\n",
       "V95          0\n",
       "\n",
       "[154 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/29 [00:09<01:31,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1.0, 'binarize': 0.0, 'class_prior': None, 'fit_prior': True}\n",
      "{'alpha': 0.01, 'binarize': None, 'class_prior': None, 'fit_prior': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 6/29 [00:21<01:27,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': None, 'splitter': 'best'}\n",
      "{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 42, 'splitter': 'best'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 10/29 [00:24<00:41,  2.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'priors': None, 'var_smoothing': 1e-09}\n",
      "{'priors': None, 'var_smoothing': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 14/29 [00:28<00:20,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}\n",
      "{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 8, 'p': 2, 'weights': 'distance'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 14/29 [00:44<00:20,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "{'C': 10000.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 2, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l1', 'random_state': 42, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 17/29 [03:05<04:12, 21.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metric': 'euclidean', 'shrink_threshold': None}\n",
      "{'metric': 'manhattan', 'shrink_threshold': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 21/29 [15:19<05:50, 43.78s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 60\u001b[0m\n\u001b[0;32m     58\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, y, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39mRANDOM_STATE)\n\u001b[0;32m     59\u001b[0m clf \u001b[39m=\u001b[39m LazyClassifierCustom(predictions\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> 60\u001b[0m models, predictions \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39;49mfit(X_train, X_test, y_train, y_test)\n\u001b[0;32m     61\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mColonna:\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mcolumn)\n\u001b[0;32m     62\u001b[0m display(models)\n",
      "Cell \u001b[1;32mIn[54], line 107\u001b[0m, in \u001b[0;36mLazyClassifierCustom.fit\u001b[1;34m(self, X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[0;32m    105\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m    106\u001b[0m n_classes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(y_train)\n\u001b[1;32m--> 107\u001b[0m parametri \u001b[39m=\u001b[39m makeTuning(model, name, X_train, y_train)\n\u001b[0;32m    108\u001b[0m \u001b[39mif\u001b[39;00m parametri \u001b[39m!=\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    109\u001b[0m     \u001b[39mprint\u001b[39m(model()\u001b[39m.\u001b[39mget_params())\n",
      "Cell \u001b[1;32mIn[52], line 32\u001b[0m, in \u001b[0;36mmakeTuning\u001b[1;34m(model, model_name, X_train, y_train)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[39mif\u001b[39;00m params \u001b[39m!=\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     30\u001b[0m     rs \u001b[39m=\u001b[39m GridSearchCV(estimator\u001b[39m=\u001b[39mmodel(), param_grid\u001b[39m=\u001b[39mparams,\n\u001b[0;32m     31\u001b[0m                         scoring\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, cv\u001b[39m=\u001b[39mskfold, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m---> 32\u001b[0m     rs\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     33\u001b[0m     params \u001b[39m=\u001b[39m rs\u001b[39m.\u001b[39mbest_params_\n\u001b[0;32m     34\u001b[0m     model \u001b[39m=\u001b[39m rs\u001b[39m.\u001b[39mbest_estimator_\n",
      "File \u001b[1;32md:\\PycharmProjects\\Thesis-Streptococcus-Classification\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32md:\\PycharmProjects\\Thesis-Streptococcus-Classification\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1378\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1379\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32md:\\PycharmProjects\\Thesis-Streptococcus-Classification\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    815\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    817\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    819\u001b[0m         )\n\u001b[0;32m    820\u001b[0m     )\n\u001b[1;32m--> 822\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    823\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    824\u001b[0m         clone(base_estimator),\n\u001b[0;32m    825\u001b[0m         X,\n\u001b[0;32m    826\u001b[0m         y,\n\u001b[0;32m    827\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    828\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    829\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    830\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    831\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    832\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    833\u001b[0m     )\n\u001b[0;32m    834\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    835\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    836\u001b[0m     )\n\u001b[0;32m    837\u001b[0m )\n\u001b[0;32m    839\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    840\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    844\u001b[0m     )\n",
      "File \u001b[1;32md:\\PycharmProjects\\Thesis-Streptococcus-Classification\\venv\\lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[1;32md:\\PycharmProjects\\Thesis-Streptococcus-Classification\\venv\\lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[1;32md:\\PycharmProjects\\Thesis-Streptococcus-Classification\\venv\\lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2544.0_x64__qbz5n2kfra8p0\\lib\\concurrent\\futures\\_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m    451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[1;32m--> 453\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2544.0_x64__qbz5n2kfra8p0\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for n in n_picchi:\n",
    "    print('DATAFRAME CON '+n+' PICCHI')\n",
    "    df = pd.read_csv(\"data/Dati_Matemaldomics_\"+n+\"picchi.csv\",\n",
    "                    delimiter=';', index_col='ID Strain')\n",
    "    n = int(n)\n",
    "    modelli = {}\n",
    "    animal  = df[['Animal species of origin']]\n",
    "    lancefield = df[['LANCEFIELD GROUP']]\n",
    "    haemolysis = df[['Haemolysis']]\n",
    "    subspecies = df[['Putative Subspecies']]\n",
    "\n",
    "    st = df[[df.columns[4]]]\n",
    "    maldi = df[df.columns[start:start+n]]\n",
    "    antibiotici = df[df.columns[start+n:start+n+n_antibiotici]]\n",
    "    geni_antibiotici = df[df.columns[start+n+n_antibiotici:start+n+n_antibiotici+n_geni]]\n",
    "    virulenza = df[df.columns[start+n+n_antibiotici+n_geni:start+n+n_antibiotici+n_geni+n_virulenza]]\n",
    "    \n",
    "    maldi.fillna(0, inplace=True)\n",
    "    maldi = maldi.replace(',', '.', regex=True)\n",
    "    columns = maldi.columns\n",
    "    for column in columns:\n",
    "        maldi[column] = maldi[column].astype(float)\n",
    "    display(maldi)\n",
    "    \n",
    "    targets = {#'antibiotici' : antibiotici,\n",
    "                #'geni_antibiotici' : geni_antibiotici,\n",
    "                'virulenza' : virulenza}\n",
    "    \n",
    "    feats_agg = {'lancefield' : lancefield,\n",
    "                'haemolysis' : haemolysis,\n",
    "                'subspecies' : subspecies,        \n",
    "                'animal' : animal}\n",
    "    \n",
    "    for str_target,target in targets.items():\n",
    "        columns = target.columns\n",
    "        for column in columns:\n",
    "            if str_target == 'antibiotici':\n",
    "                target[column] = df[column].map(map_target_antibiotici)\n",
    "            rapporto = (target[column] == 0).sum() / target.shape[0]\n",
    "            #if (antibiotici[column] == 0).all() or (antibiotici[column] == 1).all():\n",
    "            print(column+\" : \"+str(rapporto))\n",
    "            if rapporto < 0.15 or rapporto > 0.85:\n",
    "                target.drop([column], axis=1, inplace=True)\n",
    "        \n",
    "        display(target)\n",
    "        \n",
    "    metrics_df = pd.DataFrame(columns=['Target','Model','Accuracy','Precision','Recall','F1-Score','CV'])\n",
    "    metrics_df_agg = pd.DataFrame(columns=['Target','Model','Accuracy','Precision','Recall','F1-Score','CV'])\n",
    "    skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    targets['subspecies'] = subspecies\n",
    "    targets['st'] = st\n",
    "    X = maldi\n",
    "    for str_target, target in targets.items():\n",
    "        columns = target.columns\n",
    "        for column in columns:    \n",
    "            y = target[column]\n",
    "            n_classes = np.unique(y)\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)\n",
    "            clf = LazyClassifierCustom(predictions=True)\n",
    "            models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "            print(\"Colonna:\"+column)\n",
    "            display(models)\n",
    "            print(\"\\n\")\n",
    "            modelli = makeDictBest(models, modelli)\n",
    "                    \n",
    "            #models.to_csv('Risultati/LazyPredictor/model_'+str(n)+column+'.csv')\n",
    "    del targets['subspecies']\n",
    "    for str_feat, feat_agg in feats_agg.items():\n",
    "        display(feat_agg)\n",
    "        X = pd.concat([X, feat_agg], axis=1)\n",
    "        for str_target, target in targets.items():\n",
    "            columns = target.columns\n",
    "            for column in columns:    \n",
    "                y = target[column]\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)\n",
    "                clf = LazyClassifierCustom(predictions=True)\n",
    "                models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "                print(\"Colonna: \"+column+\" con feat agg: \"+str_feat)\n",
    "                display(models)\n",
    "                print(\"\\n\")\n",
    "                modelli = makeDictBest(models, modelli)\n",
    "                \n",
    "    modelli = sorted(modelli.items(), key=lambda x:x[1])\n",
    "    print(modelli)\n",
    "    display(metrics_df)\n",
    "    display(metrics_df_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "669a41511c874db11bc6497c70316204608ccf7609afcc9599fb802faa18d4d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
